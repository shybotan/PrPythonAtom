{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#импортируем необходимые модули\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_hat, y, thresh):\n",
<<<<<<< HEAD
    "    return sum((((y-1)*2)+1)==(y_hat>thresh))/sum(y)\n",
=======
    "    return sum((((y - 1) * 2) + 1) == (y_hat > thresh)) / sum(y)\n",
    "    \n",
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
    "def precision(y_hat, y, thresh):\n",
    "    return sum((((y - 1) * 2) + 1) == (y_hat > thresh)) / sum(y_hat > thresh)\n",
    "    \n",
    "def accuracy(y_hat, y, thresh):\n",
    "    return sum(y == (y_hat > thresh)) / len(y)\n",
<<<<<<< HEAD
=======
    "    \n",
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
    "def f1(y_hat, y, thresh):\n",
    "    return 2 * recall(y_hat, y , thresh) * precision(y_hat, y, thresh) / (recall(y_hat, y , thresh) + precision(y_hat, y, thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0 passed\n",
      "Test 1 passed\n",
      "Test 2 passed\n",
      "Test 3 passed\n",
      "Test 4 passed\n",
      "Test 5 passed\n",
      "Test 6 passed\n",
      "Test 7 passed\n",
      "Test 8 passed\n",
      "Test 9 passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Test {} passed\".format(i))\n",
    "    y_hat = np.random.random(30)\n",
    "    y = np.random.random(30) > 0.7\n",
    "    thresh = np.random.random()\n",
    "    \n",
    "    assert abs(recall(y_hat, y, thresh) - recall_score(y_true=y, y_pred=y_hat > thresh)) < 0.1\n",
    "    assert abs(precision(y_hat, y, thresh) - precision_score(y_true=y, y_pred=y_hat > thresh)) < 0.1\n",
    "    assert abs(accuracy(y_hat, y, thresh) - accuracy_score(y_true=y, y_pred=y_hat > thresh)) < 0.1\n",
    "    assert abs(f1(y_hat, y, thresh) - f1_score(y_true=y, y_pred=y_hat > thresh)) < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "y_hat =[1,1,1,1]\n",
    "#TODO предсказания, чтобы выбить recall 0.9 плохим классификатором\n",
    "y =[1,1,1,1]\n",
    "#TODO метки, чтобы выбить recall 0.9 плохим классификатором\n",
    "t =[1,1,1,1]\n",
    "#TODO порог, чтобы выбить recall 0.9 плохим классификатором\n",
=======
    "y_hat = #TODO предсказания, чтобы выбить recall 0.9 плохим классификатором\n",
    "y = #TODO метки, чтобы выбить recall 0.9 плохим классификатором\n",
    "t = #TODO порог, чтобы выбить recall 0.9 плохим классификатором\n",
    "\n",
    "assert recall_score(y_hat, y) > 0.9\n",
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
    "\n",
    "assert recall_score(y_hat, y, t) > 0.9\n",
    "\n",
<<<<<<< HEAD
    "y_hat = [1,1,1,1]\n",
    "#TODO предсказания, чтобы выбить precision 0.9 плохим классификатором\n",
    "y = [1,1,1,1]\n",
    "#TODO метки, чтобы выбить precision 0.9 плохим классификатором\n",
    "t = [0,0,0,0]\n",
    "#TODO порог, чтобы выбить precision 0.9 плохим классификатором\n",
=======
    "assert precision_score(y_hat, y) > 0.9\n",
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
    "\n",
    "assert precision_score(y_hat, y, t) > 0.9\n",
    "\n",
<<<<<<< HEAD
    "y_hat = [1,1,1,1]\n",
    "#TODO предсказания, чтобы выбить accuracy 0.9 плохим классификатором\n",
    "y = [1,1,1,1]\n",
    "#TODO метки, чтобы выбить accuracy 0.9 плохим классификатором\n",
    "t = [0,0,0,0]\n",
    "#TODO порог, чтобы выбить accuracy 0.9 плохим классификатором\n",
    "assert accuracy_score(y_hat, y, t) > 0.9"
=======
    "assert accuracy_score(y_hat, y) > 0.9"
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция потерь для логистической регрессии (из материалов курса по нейронным сетям)\n",
    "\n",
    "Давайте получим функцию потерь аналогичным образом, как мы это сделали с линейной регрессией.\n",
    "\n",
    "\n",
    "логарифм правдоподобия\n",
    "$$\n",
    "\\large \n",
    "\\begin{array}{rcl} \n",
    "    \\log P\\left(\\vec{y} \\mid X, \\vec{w}\\right) \n",
    "        &=& \\log \\prod_{i=1}^{\\ell} P\\left(y = y_i \\mid \\vec{x_i}, \\vec{w}\\right) \\\\ \n",
    "        &=& \\log \\prod_{i=1}^{\\ell} \\sigma(y_i\\vec{w}^T\\vec{x_i}) \\\\ \n",
    "        &=& \\sum_{i=1}^{\\ell} \\log \\sigma(y_i\\vec{w}^T\\vec{x_i}) \\\\ \n",
    "        &=& \\sum_{i=1}^{\\ell} \\log \\frac{1}{1 + \\exp^{-y_i\\vec{w}^T\\vec{x_i}}} \\\\ \n",
    "        &=& - \\sum_{i=1}^{\\ell} \\log (1 + \\exp^{-y_i\\vec{w}^T\\vec{x_i}}) \n",
    "\\end{array}\n",
    "$$\n",
    "который и будем оптимизировать. \n",
    "\n",
    "Данная функция потерь \n",
    "$$\n",
    "\\large L(\\vec{x},\\vec{y},\\vec{w}) = \\sum_{i=1}^{\\ell} \\log (1 + \\exp^{-y_i\\vec{w}^T\\vec{x_i}})\n",
    "$$\n",
    "называется логистичской функцией потерь или сокращенно logloss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дано:\n",
    "- X - обучающее множество\n",
    "- Y - метки классов для обучающего множества\n",
    "- $\\eta$ - скорость обучения\n",
    "\n",
    "Алгоритм:\n",
    "1. инициализируем $\\vec{w}_0$ небольшими случайными значениями\n",
    "2. выбираем случайный объект $x_i$ с меткой $y_i$\n",
    "3. обновляем веса $ \\vec{w}_{t+1} = \\vec{w}_{t} - \\eta \\nabla L $\n",
    "4. если условие остановки не выполнело, возвращаемся к шагу 2\n",
    "\n",
    "Выпишем градиент функции потерь:\n",
    "$$\n",
    "    \\nabla L = \\left\\{ - \\frac{y_i \\vec{x_i} }  { 1 + \\exp^{y_i\\vec{w}^T\\vec{x_i}} } + \\lambda \\vec{w} \\right\\} \n",
    "$$\n",
    "\n",
    "На практике, в качестве условия остановки, часто используют изменение функции потерь на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "selector = iris.target != 0 # ограничемся только двумя классами\n",
    "X = iris.data[:, [1,3]][selector]  # и двумя переменными\n",
    "y = iris.target[selector]\n",
    "y[y==2] = 0 # конвертируем метки классов к 1/-1\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X[:80]\n",
    "X_test = X[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polytrans = PolynomialFeatures(3)\n",
    "X_train = polytrans.fit_transform(X_train)\n",
    "X_test = polytrans.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_1 = #TODO ОБучить логистическую регрессию на train с C=0.1\n",
    "pred_1 = #TODO Предсказать логистической регрессией на трейне\n",
    "pred_test = #TODO Предсказать логистической регрессией на тесте\n",
    "#TODO Сранивть метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO обучим логистическую регрессию с разными C и посмотрим как меняются метрики на трейне и на тесте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример текстовой классификации"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 51,
=======
   "execution_count": 1,
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/home/irina/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/irina/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
=======
      "/home/kinetik/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/kinetik/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[nltk_data] Downloading package wordnet to /home/irina/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/irina/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
=======
      "[nltk_data] Downloading package wordnet to /home/kinetik/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kinetik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import grid_search\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 57,
=======
   "execution_count": 2,
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>Review</th>\n",
       "      <th>label</th>\n",
=======
       "      <th>0</th>\n",
       "      <th>1</th>\n",
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                                              Review  label\n",
       "0          2 . take around 10,000 640x480 pictures .      1\n",
       "1  i downloaded a trial version of computer assoc...      1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...      1\n",
       "3  i dont especially like how music files are uns...      0\n",
       "4  i was using the cheapie pail ... and it worked...      1"
      ]
     },
     "execution_count": 57,
=======
       "                                                   0  1\n",
       "0          2 . take around 10,000 640x480 pictures .  1\n",
       "1  i downloaded a trial version of computer assoc...  1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...  1\n",
       "3  i dont especially like how music files are uns...  0\n",
       "4  i was using the cheapie pail ... and it worked...  1"
      ]
     },
     "execution_count": 2,
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('products_sentiment_train.tsv', sep='\\t', header=None)\n",
    "data.columns=['Review','label']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Label\n",
       "0          2 . take around 10,000 640x480 pictures .      1\n",
       "1  i downloaded a trial version of computer assoc...      1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...      1\n",
       "3  i dont especially like how music files are uns...      0\n",
       "4  i was using the cheapie pail ... and it worked...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['Review', 'Label']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 59,
=======
   "execution_count": 5,
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
<<<<<<< HEAD
    "exclude=set(string.punctuation)"
=======
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Review'] = data['Review'].apply(lambda x:\n",
    "                                      \"\".join(i for i in x if i not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2  take around 10000 640x480 pictures</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail  and it worked ok...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Label\n",
       "0             2  take around 10000 640x480 pictures       1\n",
       "1  i downloaded a trial version of computer assoc...      1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...      1\n",
       "3  i dont especially like how music files are uns...      0\n",
       "4  i was using the cheapie pail  and it worked ok...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Review'] = data['Review'].apply(lambda x:\n",
    "                                      \" \".join(lemmatizer.lemmatize(i) for i in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i dont especially like how music file are unstructured basically they are just dumped into one folder with no organization like you might have in window explorer folder and subfolders'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[3, 'Review']"
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Review']=data['Review'].apply(lambda x:\" \".join(i for i in x if i not in exclude))"
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 take around 10000 640x480 picture</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music file are unst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wa using the cheapie pail and it worked ok u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Label\n",
       "0                2 take around 10000 640x480 picture      1\n",
       "1  i downloaded a trial version of computer assoc...      1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...      1\n",
       "3  i dont especially like how music file are unst...      0\n",
       "4  i wa using the cheapie pail and it worked ok u...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer().fit(data['Review'])"
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-61-97941a881e37>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-61-97941a881e37>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    data['Review']=data['Review'].apply(lambda x:\" \".join(lemmatizer.lemmatizer(i)for i in x.split())\u001b[0m\n\u001b[0m                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "data['Review']=data['Review'].apply(lambda x:\" \".join(lemmatizer.lemmatizer(i)for i in x.split())"
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.transform(data['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-96cd105718ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \"\"\"\n\u001b[0;32m--> 836\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m    812\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "vectorizer=CountVectorizer().fit(data['Review'])\n",
    "features=vectorizer.transform(data['Review'])"
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x3750 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 29300 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 53,
   "metadata": {},
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(features, data.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_ = \"unfortunately\t\"\n",
    "vector_review = vectorizer.transform([review_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Position\n",
       "0      10         0\n",
       "1     100         1\n",
       "2    1000         2\n",
       "3   10000         3\n",
       "4    1011         4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction_ = [ (k, v) for k, v in vectorizer.vocabulary_.items()]\n",
    "diction_.sort(key=lambda x: x[1])\n",
    "diction_ = pd.DataFrame(diction_, columns=['Feature', 'Position'])\n",
    "diction_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "diction_['Weight'] = clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Position</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>unfortunately</td>\n",
       "      <td>3463</td>\n",
       "      <td>-1.520205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>button</td>\n",
       "      <td>551</td>\n",
       "      <td>-1.476389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>only</td>\n",
       "      <td>2282</td>\n",
       "      <td>-1.464573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>useless</td>\n",
       "      <td>3511</td>\n",
       "      <td>-1.430956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>annoying</td>\n",
       "      <td>277</td>\n",
       "      <td>-1.383232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>scratch</td>\n",
       "      <td>2877</td>\n",
       "      <td>-1.381335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>worst</td>\n",
       "      <td>3704</td>\n",
       "      <td>-1.343708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>norton</td>\n",
       "      <td>2210</td>\n",
       "      <td>-1.310950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>isn</td>\n",
       "      <td>1751</td>\n",
       "      <td>-1.296755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>after</td>\n",
       "      <td>224</td>\n",
       "      <td>-1.178989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>would</td>\n",
       "      <td>3709</td>\n",
       "      <td>-1.162639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>con</td>\n",
       "      <td>741</td>\n",
       "      <td>-1.112930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>viewfinder</td>\n",
       "      <td>3553</td>\n",
       "      <td>-1.099735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>weak</td>\n",
       "      <td>3609</td>\n",
       "      <td>-1.090117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>not</td>\n",
       "      <td>2213</td>\n",
       "      <td>-1.086237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>doesn</td>\n",
       "      <td>1028</td>\n",
       "      <td>-1.086146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>sometimes</td>\n",
       "      <td>3075</td>\n",
       "      <td>-1.082759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>difficult</td>\n",
       "      <td>974</td>\n",
       "      <td>-1.035903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>mediasource</td>\n",
       "      <td>2022</td>\n",
       "      <td>-1.034496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>off</td>\n",
       "      <td>2260</td>\n",
       "      <td>-1.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>jack</td>\n",
       "      <td>1765</td>\n",
       "      <td>-1.029345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>nt</td>\n",
       "      <td>2229</td>\n",
       "      <td>-1.021854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>customer</td>\n",
       "      <td>862</td>\n",
       "      <td>-0.995417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>them</td>\n",
       "      <td>3313</td>\n",
       "      <td>-0.991234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>folder</td>\n",
       "      <td>1332</td>\n",
       "      <td>-0.988468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>internet</td>\n",
       "      <td>1729</td>\n",
       "      <td>-0.982398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>month</td>\n",
       "      <td>2098</td>\n",
       "      <td>-0.937442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>cause</td>\n",
       "      <td>599</td>\n",
       "      <td>-0.936905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>junk</td>\n",
       "      <td>1787</td>\n",
       "      <td>-0.925199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>they</td>\n",
       "      <td>3319</td>\n",
       "      <td>-0.917989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>small</td>\n",
       "      <td>3045</td>\n",
       "      <td>0.828031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>extremely</td>\n",
       "      <td>1228</td>\n",
       "      <td>0.831151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>ever</td>\n",
       "      <td>1174</td>\n",
       "      <td>0.836183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>here</td>\n",
       "      <td>1557</td>\n",
       "      <td>0.856748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>light</td>\n",
       "      <td>1876</td>\n",
       "      <td>0.894969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>m12v</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.896874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>big</td>\n",
       "      <td>456</td>\n",
       "      <td>0.943533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>ok</td>\n",
       "      <td>2270</td>\n",
       "      <td>0.945523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>pocket</td>\n",
       "      <td>2475</td>\n",
       "      <td>0.962952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>perfectly</td>\n",
       "      <td>2405</td>\n",
       "      <td>0.967403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>best</td>\n",
       "      <td>449</td>\n",
       "      <td>1.039063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>3686</td>\n",
       "      <td>1.046854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>amazing</td>\n",
       "      <td>264</td>\n",
       "      <td>1.056289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>pleased</td>\n",
       "      <td>2463</td>\n",
       "      <td>1.079783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>over</td>\n",
       "      <td>2335</td>\n",
       "      <td>1.113875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>1.134415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>decent</td>\n",
       "      <td>894</td>\n",
       "      <td>1.144143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>hold</td>\n",
       "      <td>1583</td>\n",
       "      <td>1.174816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>plus</td>\n",
       "      <td>2472</td>\n",
       "      <td>1.213384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>feature</td>\n",
       "      <td>1267</td>\n",
       "      <td>1.218549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>cool</td>\n",
       "      <td>799</td>\n",
       "      <td>1.226490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>awesome</td>\n",
       "      <td>373</td>\n",
       "      <td>1.240141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>good</td>\n",
       "      <td>1452</td>\n",
       "      <td>1.286287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>price</td>\n",
       "      <td>2541</td>\n",
       "      <td>1.324726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>happy</td>\n",
       "      <td>1511</td>\n",
       "      <td>1.419334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>perfect</td>\n",
       "      <td>2404</td>\n",
       "      <td>1.459626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>easy</td>\n",
       "      <td>1094</td>\n",
       "      <td>1.530372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1189</td>\n",
       "      <td>1.535779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>love</td>\n",
       "      <td>1943</td>\n",
       "      <td>1.797911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>great</td>\n",
       "      <td>1467</td>\n",
       "      <td>2.054222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3750 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Feature  Position    Weight\n",
       "3463  unfortunately      3463 -1.520205\n",
       "551          button       551 -1.476389\n",
       "2282           only      2282 -1.464573\n",
       "3511        useless      3511 -1.430956\n",
       "277        annoying       277 -1.383232\n",
       "2877        scratch      2877 -1.381335\n",
       "3704          worst      3704 -1.343708\n",
       "2210         norton      2210 -1.310950\n",
       "1751            isn      1751 -1.296755\n",
       "224           after       224 -1.178989\n",
       "3709          would      3709 -1.162639\n",
       "741             con       741 -1.112930\n",
       "3553     viewfinder      3553 -1.099735\n",
       "3609           weak      3609 -1.090117\n",
       "2213            not      2213 -1.086237\n",
       "1028          doesn      1028 -1.086146\n",
       "3075      sometimes      3075 -1.082759\n",
       "974       difficult       974 -1.035903\n",
       "2022    mediasource      2022 -1.034496\n",
       "2260            off      2260 -1.030000\n",
       "1765           jack      1765 -1.029345\n",
       "2229             nt      2229 -1.021854\n",
       "862        customer       862 -0.995417\n",
       "3313           them      3313 -0.991234\n",
       "1332         folder      1332 -0.988468\n",
       "1729       internet      1729 -0.982398\n",
       "2098          month      2098 -0.937442\n",
       "599           cause       599 -0.936905\n",
       "1787           junk      1787 -0.925199\n",
       "3319           they      3319 -0.917989\n",
       "...             ...       ...       ...\n",
       "3045          small      3045  0.828031\n",
       "1228      extremely      1228  0.831151\n",
       "1174           ever      1174  0.836183\n",
       "1557           here      1557  0.856748\n",
       "1876          light      1876  0.894969\n",
       "1960           m12v      1960  0.896874\n",
       "456             big       456  0.943533\n",
       "2270             ok      2270  0.945523\n",
       "2475         pocket      2475  0.962952\n",
       "2405      perfectly      2405  0.967403\n",
       "449            best       449  1.039063\n",
       "3686      wonderful      3686  1.046854\n",
       "264         amazing       264  1.056289\n",
       "2463        pleased      2463  1.079783\n",
       "2335           over      2335  1.113875\n",
       "25               15        25  1.134415\n",
       "894          decent       894  1.144143\n",
       "1583           hold      1583  1.174816\n",
       "2472           plus      2472  1.213384\n",
       "1267        feature      1267  1.218549\n",
       "799            cool       799  1.226490\n",
       "373         awesome       373  1.240141\n",
       "1452           good      1452  1.286287\n",
       "2541          price      2541  1.324726\n",
       "1511          happy      1511  1.419334\n",
       "2404        perfect      2404  1.459626\n",
       "1094           easy      1094  1.530372\n",
       "1189      excellent      1189  1.535779\n",
       "1943           love      1943  1.797911\n",
       "1467          great      1467  2.054222\n",
       "\n",
       "[3750 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction_.sort_values('Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3750 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 26 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(vector_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
>>>>>>> 14b08ea2d31f2f1750730bb79b286ad64a775cbf
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "porter_stemmer = PorterStemmer()\n",
    "for i in range(0,len(data)):\n",
    "    arr = data.iloc[i,0].split(' ')\n",
    "    data.iloc[i,0] = ' '.join([str(porter_stemmer.stem(wordnet_lemmatizer.lemmatize(arr[i]))) for i in range(0, len(arr))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a90e9a71481d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vectorizer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mgrid_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mgrid_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Classifier: logReg, vectoizer: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m', best_score: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 for train, test in cv)\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vectors = [CountVectorizer(), TfidfVectorizer()]\n",
    "parameters_grid = {\n",
    "    'vectorizer__stop_words' : [nltk.corpus.stopwords.words('english'), 'english', None],\n",
    "    'vectorizer__ngram_range' : [(1,2), (1,3)],\n",
    "    'classifier__C':[0.25,0.5,1,2,5,10,15],\n",
    "    'classifier__class_weight':['balanced', None],\n",
    "    'classifier__max_iter':[70,100,200],\n",
    "    'classifier__penalty':['l2','l1']\n",
    "}\n",
    "for vect in vectors:\n",
    "        pipeline = Pipeline([('vectorizer', vect),('classifier',LogisticRegression())])\n",
    "        grid_cv = grid_search.GridSearchCV(pipeline, parameters_grid, n_jobs=-1, scoring = 'accuracy', cv = 3)\n",
    "        grid_cv.fit(data[0],data[1])\n",
    "        print('Classifier: logReg, vectoizer: ',vect,', best_score: ',grid_cv.best_score_, grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('products_sentiment_test.tsv', sep='\\t')\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(data_test)):\n",
    "    arr = data_test.iloc[i,1].split(' ')\n",
    "    data_test.iloc[i,1] = ' '.join([str(porter_stemmer.stem(wordnet_lemmatizer.lemmatize(arr[i].lower()))) for i in range(0, len(arr))])\n",
    "res = clf.predict(vectorizer.transform(data_test.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Appendix TODO together. Классификация отзывов о технике на русском"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
